---
layout: reveal_markdown
title: "Scalable computing in genomics"
tags: slides 
date: 2021-12-09
---

<style>
	.reveal {font-size: 2.2em;}
</style>

# {{ page.title }}
---
Remember this?
<iframe src="https://databio.org/seqcosts/cost.html" width="1200" height="550"></iframe>
<a style="font-size:0.6em" href="https://databio.org/seqcosts">databio.org/seqcosts</a>

---
Lower costs &rarr; More data

<iframe src="https://databio.org/seqcosts/sra.html" width="950" height="550"></iframe>
<a style="font-size:0.6em" href="https://databio.org/seqcosts">databio.org/seqcosts</a>

---
### Scalable computing in genomics

Genomics can be 'big data'.<br>

<img src="images/scalable-computing-genomics/performance-importance-heatmap.svg" height="400" style="background:white">

---

### Approaches for scalability

1. Parallelization
2. Optimization
3. Databases
4. Compression

---
## Parallelization

> Splitting a compute task, and then completing each split simultaneously. 

---
### split-apply-combine

<img src="images/scalable-computing-genomics/split-apply-combine.svg" height="400" style="background:white">

- Many problems call for a similar computing architecture
- *e.g.* MapReduce/Hadoop

---

<h3>Scopes of parallelism</h3>
<img src="images/scalable-computing-genomics/parallel_sequential.svg" width="100%">
<div class="row" style="margin:0; padding:0">
<div class="col fragment" style="background-color:#211">by process
<img src="images/scalable-computing-genomics/parallel_process.svg" width="300">
</div>
<div class="col fragment" style="background-color:#112">by sample
<img src="images/scalable-computing-genomics/parallel_sample.svg" width="300">
</div>
<div class="col fragment" style="background-color:#121">by dependence
<img src="images/scalable-computing-genomics/parallel_dependency.svg" width="300">
</div>
</div>

---
<img src="images/scalable-computing-genomics/parallel_process.svg" height="100" style="float:right">

### Parallel by process


PROs:
- easy to use if the tool can do it (*e.g.* `-c 16`)
- relatively easy in R or Python

CON:
- node-threaded parallelism (restricted to a single node)
- typically built-in to a tool, so limited by tool capacity

---
### Aside: Cluster hardware

<img src="images/scalable-computing-genomics/cluster-hardware.svg" height="400">


---
<img src="images/scalable-computing-genomics/parallel_sample.svg" height="100" style="float:right">

### Parallel by sample/job

PRO:
- no shared memory; limited only by cluster size
- HPC clusters are intended for this type of parallelization
- Restricted by size of HPC, rather than node (burst to cloud)
- Doesn't depend on the tool

CON:
- requires independence of jobs

---
<img src="images/scalable-computing-genomics/parallel_dependency.svg" height="100" style="float:right">


### Parallel by dependency

PRO:
- not necessarily node-threaded

CON:
- may have shared file-system requirements
- requires a dependency graph of workflow steps
- requires a layer of task management above typical HPC usage
- limited to independent workflow elements
- requires independence of jobs

---

<h3>Scopes of parallelism: tradeoffs</h3>
<img src="images/scalable-computing-genomics/parallel_sequential.svg" width="100%">
<div class="row" style="margin:0; padding:0">
<div class="col" style="background-color:#211">by process
<img src="images/scalable-computing-genomics/parallel_process.svg" width="300">
</div>
<div class="col" style="background-color:#112">by sample
<img src="images/scalable-computing-genomics/parallel_sample.svg" width="300">
</div>
<div class="col" style="background-color:#121">by dependence
<img src="images/scalable-computing-genomics/parallel_dependency.svg" width="300">
</div>
</div>

<div class="row frament">
<div class="col" style="background-color:#211">Very easy</div>
<div class="col" style="background-color:#112">Easy</div>
<div class="col" style="background-color:#121">Hard</div>
</div>

<div class="row fragment">
<div class="col" style="background-color:#211">
<img src="images/scalable-computing-genomics/parallel_process_benefit.svg" width="250">
</div>
<div class="col" style="background-color:#112">
<img src="images/scalable-computing-genomics/parallel_sample_benefit.svg" width="250">
</div>
<div class="col" style="background-color:#121">
<img src="images/scalable-computing-genomics/parallel_dependency_benefit.svg" width="250">
</div>
</div>

---
### Parallel processing in R

- [parallel]() package (part of Core R)

```R
mclapply(data, function, mc.cores=detectCores())
```

---
### Parallel jobs in R

- BatchJobs
- snow

---
### Parallel processing in Python

- subprocess module
- multiprocessing module
- threading module

---
### Workflows

> A workflow or pipeline is a repeatable sequence of tasks that process a piece of data. 

<div class="mermaid">
flowchart LR
  Data --> Task1 --> Task2 --> Task3 --> Output
</div>
---
### Workflow spectrum

![](images/scalable-computing-genomics/pipeline_spectrum.svg)

---
#### Workflow/pipeline engine/framework

> A development toolkit that makes it easier to build workflows.

- Snakemake
- Nextflow
- Common Workflow Language

---
### Snakemake

---
### Nextflow

---
### Common workflow language

---
### Stop writing shell scripts!

- Shell scripting language is difficult to write
- As a corollary, shell scripts are also generally difficult to read
- Shell scripting lacks the features in a full-service language

---
> The shell makes common and simple actions really simple, at the expense of making more complex things much more complex.

---
> Typically, a small shell script will be shorter and simpler than the corresponding python program, but the python program will tend to gracefully accept modifications, whereas the shell script will tend to get less and less maintainable as code is added.

---
> This has the consequence that for optimal day-to-day productivity you need shell-scripting, but you should use it mostly for throwaway scripts, and use python everywhere else. -Anonymous

---
## 2. Optimization

---
![](images/scalable-computing-genomics/bigocheatsheet.png)

Source: https://www.bigocheatsheet.com/



1. algorithm complexity
2. language choice and quirks
3. 


---
### Use vectorized loops in R

```R
library("microbenchmark")
d = matrix(rnorm(10000000), 10, 1000000)
myMeans = function(d) {
	means = c()
	for (i in 1:1000000) {		means[i] = mean(d[,i])	}
	means
}

microbenchmark(	
	myMeans(d),
	apply(d, 2, mean),
	colMeans(d),
	times=3)

Unit: milliseconds
              expr  min   lq mean median   uq   max neval
        myMeans(d) 4693 4880 4997   5067 5149  5230     3
 apply(d, 2, mean) 4856 5047 5152   5237 5300  5363     3
       colMeans(d)    7    7    7      7    7     8     3
```

---
Tabix indexing

Input:
```
chr1    10468   annotation1
chr1    10469   annotation2
chr1    10470   annotation3
```

Compress: `bgzip file.tsv`  
Index: `tabix -s 1 -b 2 -e 2 file.tsv.gz`  
Retrieve: `tabix file.tsv.gz.tbi chr5:50000-100000` 

See [Tabix Bioinformatics paper](https://doi.org/10.1093/bioinformatics/btq671)

---
BigBed and BigWig

- Compressed and Indexed versions of BED and WIG files.
- Compresed: makes the files much smaller.
- Indexed: Random access allows reading specific chunks
